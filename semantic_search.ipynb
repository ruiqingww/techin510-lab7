{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence_transformers) (4.40.2)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence_transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence_transformers) (2.3.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence_transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence_transformers) (1.13.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence_transformers) (0.23.0)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence_transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/eileenwang/Library/Python/3.11/lib/python/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/eileenwang/Library/Python/3.11/lib/python/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.4.28)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name Supabase/gte-small. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8526]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "sentences = [\n",
    "    'The new movie is awesome',\n",
    "    'The movie is bad',\n",
    "]\n",
    "\n",
    "model = SentenceTransformer('Supabase/gte-small')\n",
    "embeddings = model.encode(sentences)\n",
    "print(cos_sim(embeddings[0], embeddings[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits outside \t\t love \t\t Score: 0.7535\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: 0.7016\n",
      "The new movie is awesome \t\t The new movie is awesome \t\t Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Two lists of sentences\n",
    "sentences1 = [\n",
    "    \"The cat sits outside\",\n",
    "    \"A man is playing guitar\",\n",
    "    \"The new movie is awesome\",\n",
    "]\n",
    "\n",
    "sentences2 = [\n",
    "    \"love\",\n",
    "    \"A woman watches TV\",\n",
    "    \"The new movie is awesome\",\n",
    "]\n",
    "\n",
    "# Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "# Compute cosine-similarities\n",
    "cosine_scores = cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "# Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(\n",
    "        sentences1[i], sentences2[i], cosine_scores[i][i]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This framework generates embeddings for each input sentence\n",
      "Embedding: [-4.56867278e-01 -6.03743829e-02  2.77015176e-02 -1.49323866e-01\n",
      " -2.58533154e-02  3.99035305e-01 -1.55860940e-02  2.39103645e-01\n",
      "  9.95151997e-02  1.49658024e-01 -3.45251888e-01 -4.33488995e-01\n",
      "  6.84537292e-01  2.49792680e-01  3.92542332e-01  3.05619448e-01\n",
      " -2.38010854e-01  3.97296160e-01 -4.60436374e-01 -1.37540281e-01\n",
      "  5.90817690e-01 -2.84304172e-01  1.05978377e-01 -5.92266321e-01\n",
      " -1.59350619e-01  4.13091779e-01 -1.64931804e-01 -7.34143332e-02\n",
      " -3.01011860e-01 -1.89854729e+00  2.36651190e-02 -5.51726282e-01\n",
      "  7.99841821e-01 -4.33841310e-02 -2.60188133e-01 -1.74995974e-01\n",
      " -4.91537094e-01  4.09644186e-01 -1.80871487e-01  2.30171070e-01\n",
      "  2.36195013e-01  2.71462440e-01  2.17980817e-02 -6.09191835e-01\n",
      " -2.04823956e-01 -5.56082726e-01 -6.08014226e-01  7.80064292e-05\n",
      " -8.24697465e-02 -2.05188379e-01 -7.09769279e-02 -4.21118736e-01\n",
      " -9.76333469e-02  8.62650350e-02  2.12224558e-01  1.12527497e-01\n",
      "  2.59943962e-01  3.95329177e-01 -6.50232956e-02  5.24258018e-01\n",
      "  1.58541828e-01  4.68619645e-01 -1.60996568e+00  5.79657197e-01\n",
      "  1.82124645e-01  2.42382601e-01 -4.06524211e-01  1.22554023e-02\n",
      "  2.72296727e-01  5.30596316e-01 -3.37541103e-01 -4.78775874e-02\n",
      "  2.59612203e-01  4.71693099e-01  2.81485021e-01  1.52577341e-01\n",
      "  9.92466360e-02 -1.39527410e-01 -4.11879197e-02  5.20228930e-02\n",
      "  3.23796809e-01 -2.65384823e-01 -5.11669107e-02  3.42374407e-02\n",
      " -1.43446103e-01 -5.09975374e-01  1.55710921e-01 -2.35872656e-01\n",
      " -4.35056761e-02  3.50880086e-01 -5.47972322e-01 -5.08297384e-01\n",
      " -3.16381812e-01  1.15920254e-03 -5.00386477e-01 -5.21113813e-01\n",
      "  3.75755817e-01  4.98317741e-02 -1.33606836e-01  1.78634346e+00\n",
      " -3.26684773e-01  2.85228103e-01  7.18686759e-01 -4.38250363e-01\n",
      " -1.70283854e-01 -2.76614487e-01 -1.32212698e-01 -3.22370231e-01\n",
      " -3.83464694e-01 -2.78658159e-02 -4.44753855e-01 -2.85759002e-01\n",
      "  1.71467345e-02 -3.30873132e-01  4.65809032e-02  1.69578150e-01\n",
      "  5.99637330e-01  3.47425967e-01 -3.55501294e-01  7.54840821e-02\n",
      " -4.10687298e-01  3.28011334e-01 -1.10068686e-01 -1.32470757e-01\n",
      "  5.74034154e-01 -5.71512103e-01  2.90203154e-01  1.01862645e+00\n",
      "  6.40651405e-01  2.30927259e-01  2.66996115e-01  2.24936023e-01\n",
      " -4.76751775e-01 -1.49021268e-01  8.05406719e-02  1.35307848e-01\n",
      " -2.00533852e-01  1.18563265e-01  3.99001122e-01 -2.92768687e-01\n",
      " -2.33607993e-01 -2.42962509e-01 -1.13435283e-01 -6.31409585e-01\n",
      " -4.77168292e-01  1.37608528e+00 -3.04477155e-01  6.80686533e-03\n",
      " -5.31206787e-01  3.52248400e-01 -1.87674135e-01  3.89591575e-01\n",
      "  4.52504829e-02 -2.45993584e-01  1.94721043e-01  8.00189674e-01\n",
      "  7.90387839e-02  9.53514501e-03 -2.86596268e-01  3.69423062e-01\n",
      " -4.25559096e-02 -1.92183316e-01 -2.00948820e-01  9.79480863e-01\n",
      "  2.96697229e-01 -1.23254609e+00 -3.79993737e-01  2.22383916e-01\n",
      "  3.23136926e-01 -6.07404649e-01  4.72589493e-01  3.09091419e-01\n",
      " -5.50811529e-01  3.19621593e-01  4.41805571e-01  1.14194170e-01\n",
      " -4.87645358e-01 -1.39144391e-01  4.53901142e-01  7.00235665e-02\n",
      "  4.77286845e-01 -4.70286816e-01 -6.89326823e-01  4.99393821e-01\n",
      "  1.56330526e-01 -5.49709439e-01 -1.88677326e-01 -6.90059960e-01\n",
      "  4.75550532e-01  5.82958059e-03 -2.16637760e-01  2.66476870e-01\n",
      " -3.53904873e-01  2.08952259e-02 -4.48043168e-01 -5.31971633e-01\n",
      " -3.88412848e-02 -3.79733920e-01  1.35392964e-01 -3.34814370e-01\n",
      "  3.14223886e-01  4.12584007e-01 -2.61760592e-01  3.95280182e-01\n",
      " -5.43952622e-02 -1.61435425e-01 -1.91246774e-02  8.95765871e-02\n",
      "  4.78389084e-01  2.42170632e-01 -8.53364915e-02  6.83253184e-02\n",
      "  6.71625853e-01  4.27292548e-02 -2.41716325e-01 -9.03944597e-02\n",
      " -1.37356609e-01  2.58292854e-01  5.76493204e-01  4.62749153e-01\n",
      " -1.16126193e-02 -6.08127117e-01 -3.93039018e-01 -1.94645071e+00\n",
      "  2.39377394e-01  4.13058877e-01 -2.93526351e-01  2.46926129e-01\n",
      " -7.40389585e-01  2.08985880e-01 -8.36009979e-02  2.18448535e-01\n",
      "  5.32945335e-01  4.47731704e-01 -2.82743096e-01  3.89210761e-01\n",
      "  5.63034452e-02 -4.37620208e-02  5.77856958e-01  1.54077828e-01\n",
      "  1.83482870e-01 -9.55360755e-02  1.23805083e-01  1.00321919e-01\n",
      "  1.32524997e-01  1.28930788e-02 -6.07730150e-01  2.25442991e-01\n",
      " -2.96389639e-01  2.30188584e+00  6.72613442e-01  3.76602858e-01\n",
      " -5.05816698e-01  6.14272177e-01  5.98954689e-03 -2.66410410e-01\n",
      " -1.42900789e+00  6.60268486e-01 -9.31876600e-02  2.29691640e-01\n",
      "  2.68720031e-01 -2.67337292e-01 -1.09166533e-01 -1.23028569e-01\n",
      "  1.26052886e-01 -1.43317804e-01 -9.47891116e-01 -2.08331689e-01\n",
      " -5.25782824e-01 -3.66916507e-01 -2.29024515e-01 -3.88984501e-01\n",
      "  5.34259856e-01  1.19654857e-01 -3.49710017e-01  5.15760005e-01\n",
      "  1.75840080e-01 -4.78294402e-01 -3.34120452e-01 -8.25947404e-01\n",
      "  3.32600892e-01 -5.73986232e-01  1.12896629e-01  1.80806085e-01\n",
      " -2.74246067e-01  4.36670985e-03 -6.28200114e-01  4.32769030e-01\n",
      " -4.11718637e-02  2.20929414e-01 -4.68097031e-01  9.62069407e-02\n",
      " -1.45118609e-01 -3.28893840e-01  5.72104096e-01 -4.66822773e-01\n",
      " -9.30137709e-02  5.55711031e-01  9.67605859e-02  4.62879315e-02\n",
      "  7.22684525e-03 -3.55116218e-01 -3.17167729e-01  6.87639952e-01\n",
      " -2.78592855e-01  4.22087073e-01  3.03655028e-01  5.24843931e-01\n",
      "  2.47491360e-01  4.95159268e-01  7.93321207e-02  6.70929909e-01\n",
      " -2.17288971e-01  9.52392891e-02  3.29661407e-02 -3.77907455e-01\n",
      "  3.47616151e-02  1.69545278e-01 -3.36123735e-01 -2.77338934e+00\n",
      "  3.24785709e-01 -5.46860509e-02 -1.93837099e-02  6.61712736e-02\n",
      "  2.35489741e-01  2.50874758e-01  2.25246906e-01 -1.78854614e-01\n",
      "  1.75257459e-01  2.54051119e-01  5.88983715e-01  1.96750984e-01\n",
      " -2.62854636e-01 -5.62368073e-02  3.37912858e-01  8.55532765e-01\n",
      " -4.45742816e-01  3.16888750e-01 -7.20420182e-01  2.40451440e-01\n",
      "  3.42440307e-01  1.93734550e+00 -1.86349958e-01  3.75419110e-01\n",
      " -1.92953035e-01 -3.35578509e-02 -1.77298933e-01  5.67700684e-01\n",
      " -6.26206920e-02  6.16321899e-02  4.63653989e-02  7.81068921e-01\n",
      " -1.96706772e-01  2.16229949e-02  2.37794906e-01 -1.29566357e-01\n",
      "  3.18871647e-01  3.59903038e-01 -9.10093784e-02 -1.50138021e-01\n",
      " -2.20959842e-01 -5.63868463e-01 -1.93404898e-01  3.70330870e-01\n",
      " -8.86172503e-02  3.30338180e-01 -2.99676716e-01 -7.41068646e-02\n",
      "  1.38372287e-01 -1.74606472e-01  3.38766426e-02  1.14063270e-01\n",
      " -2.06782650e-02  2.43284702e-01  1.46819651e-01  4.23554257e-02\n",
      " -2.78456777e-01 -2.98639178e-01 -6.27654120e-02 -1.86697729e-02\n",
      " -4.48014557e-01 -4.04818505e-02  4.76228714e-01  7.22660683e-03]\n",
      "\n",
      "Sentence: Sentences are passed as a list of string.\n",
      "Embedding: [-3.93862605e-01 -3.52358781e-02  2.19509259e-01 -2.07814410e-01\n",
      " -1.82300314e-01  1.97449606e-02  6.93794310e-01  3.43922228e-01\n",
      "  2.10592613e-01 -2.43807510e-01  9.12736915e-03 -2.87090421e-01\n",
      "  5.73660135e-01  1.51828706e-01 -2.12550089e-02  9.25378874e-02\n",
      " -9.50912386e-03 -2.71742512e-02 -8.06861281e-01  1.99536517e-01\n",
      "  7.10039198e-01  3.69407475e-01  1.52606284e-02 -2.38921940e-01\n",
      "  2.27182955e-01  6.45986855e-01 -9.64695439e-02 -4.02615726e-01\n",
      " -5.04842043e-01 -1.42578280e+00 -2.26190343e-01 -7.54248619e-01\n",
      "  3.14552307e-01  1.05107029e-03 -1.58944800e-01 -8.66189823e-02\n",
      " -3.19319785e-01  4.58901674e-01 -6.04273796e-01  3.81100655e-01\n",
      "  3.82963687e-01  3.55839461e-01  5.57986610e-02 -3.66868794e-01\n",
      " -2.65462667e-01 -5.72685957e-01 -4.31849986e-01 -1.45792216e-01\n",
      "  3.86427492e-01 -4.62429732e-01 -2.80395418e-01 -1.06174231e-01\n",
      "  3.00766397e-02  1.17140859e-01  1.84592023e-01  1.05639361e-01\n",
      "  3.80688310e-01  3.02562326e-01  1.60874471e-01  2.09809110e-01\n",
      "  1.41846880e-01  1.91590115e-01 -1.92381012e+00  9.10789490e-01\n",
      " -7.59847239e-02  7.17373565e-02 -1.34398222e-01 -2.66134560e-01\n",
      " -9.95745603e-03  6.83404565e-01 -4.41037044e-02  8.73199180e-02\n",
      "  1.35615826e-01  6.77331448e-01  2.11982638e-01 -2.81132370e-01\n",
      " -9.76243913e-02 -4.75875169e-01  1.40326887e-01  1.84948862e-01\n",
      "  2.01146230e-01 -3.02375466e-01 -1.27712667e-01 -1.98757350e-01\n",
      " -3.31271619e-01 -2.10801467e-01 -1.72115546e-02 -3.14732313e-01\n",
      "  1.59955323e-01  1.16150759e-01 -4.73638088e-01 -3.06396186e-01\n",
      "  3.32814530e-02  1.28075853e-01 -5.94812751e-01 -5.38974762e-01\n",
      "  2.55304545e-01  2.35481650e-01  2.77927518e-01  1.86098588e+00\n",
      " -6.22874200e-01  2.36852393e-01  4.40797895e-01 -6.05650365e-01\n",
      "  2.71148652e-01  2.54129581e-02  2.58865301e-02 -6.94639623e-01\n",
      " -3.52372080e-01 -8.91452208e-02 -3.73842984e-01 -1.32315889e-01\n",
      "  6.21244073e-01 -4.26418781e-01  2.38745227e-01  5.21675721e-02\n",
      "  5.79382300e-01  3.62239666e-02 -3.10878009e-01 -6.93729669e-02\n",
      " -2.77093172e-01  1.38488099e-01  1.90860882e-01 -8.67401585e-02\n",
      " -4.34843153e-02 -4.55432862e-01  4.19670463e-01  8.17591906e-01\n",
      "  4.23855573e-01  4.12658006e-01  5.84360898e-01 -2.73476899e-01\n",
      " -2.99523085e-01 -8.59530047e-02 -8.54552463e-02  4.32939082e-02\n",
      "  2.83115357e-01  1.79033577e-01  3.76164794e-01 -4.58685756e-01\n",
      " -3.45038444e-01 -1.14092982e+00 -2.66722471e-01 -6.97936475e-01\n",
      " -3.35548490e-01  1.32581043e+00 -3.06414157e-01  2.06428334e-01\n",
      " -6.22677386e-01  1.36585727e-01 -1.22536151e-02  2.34815061e-01\n",
      "  4.34671998e-01 -5.96832871e-01  8.08058959e-03  2.68486053e-01\n",
      "  3.47632855e-01  3.28054786e-01 -2.19390720e-01  2.49658395e-02\n",
      "  1.23883344e-01  1.11144394e-01 -3.51211339e-01  9.04265642e-01\n",
      "  2.08525226e-01 -6.53281927e-01 -1.26098439e-01  3.32494467e-01\n",
      "  1.58731654e-01 -5.52374661e-01  5.38156152e-01  1.74560979e-01\n",
      " -5.65634310e-01  1.92411959e-01  2.35231057e-01  5.94955683e-01\n",
      " -2.14915708e-01 -3.14546317e-01  4.15746570e-02  3.77353802e-02\n",
      "  2.96163321e-01 -1.39099151e-01 -5.23051560e-01  4.18562800e-01\n",
      "  2.80739754e-01 -3.89157742e-01 -4.09879088e-01 -4.47767168e-01\n",
      "  3.96111846e-01  1.31934896e-01 -4.32596654e-01  1.71006247e-01\n",
      " -4.29314733e-01 -2.06102625e-01 -6.11792028e-01 -1.84269339e-01\n",
      "  4.09945309e-01 -3.49657804e-01 -1.32814139e-01 -1.15239114e-01\n",
      "  2.61273831e-01  3.64553183e-01 -2.64315903e-01  1.68294445e-01\n",
      "  2.50362784e-01 -3.48269463e-01 -2.07520187e-01  6.83054924e-02\n",
      "  3.17614853e-01  9.42584574e-02 -2.53588021e-01  2.33532608e-01\n",
      "  5.21976292e-01  4.18914519e-02 -4.09775347e-01 -7.39687026e-01\n",
      " -1.65423334e-01  2.25157440e-01  6.10525668e-01  4.04132843e-01\n",
      "  1.50949578e-03 -8.55741441e-01 -1.81252971e-01 -1.92044377e+00\n",
      "  3.94439436e-02  5.51029563e-01 -3.65431517e-01  5.50953150e-01\n",
      " -4.65819538e-01  9.35810581e-02  3.55439284e-03  2.60322839e-01\n",
      "  3.91171545e-01  3.69053394e-01 -5.63485384e-01  8.93277824e-02\n",
      " -2.02799663e-01  1.80353690e-02  6.27710521e-01 -6.33408800e-02\n",
      " -3.01744062e-02  9.57548618e-02  2.37751186e-01 -9.03228819e-02\n",
      "  9.23252553e-02  5.93230408e-03 -4.08131808e-01  1.61560342e-01\n",
      " -1.64112851e-01  2.24788427e+00  6.57912254e-01  1.46100298e-01\n",
      " -2.76762515e-01  7.32800841e-01  2.06444561e-01  1.10379020e-02\n",
      " -1.09926498e+00  8.10583830e-01 -1.38519704e-03  2.69954521e-02\n",
      "  4.02314030e-02 -1.00958325e-01 -1.72586456e-01 -9.96778458e-02\n",
      "  4.04210597e-01 -5.41352868e-01 -5.59271812e-01  1.26824761e-02\n",
      " -5.15469193e-01 -1.51045382e-01 -4.08096045e-01 -9.81941968e-02\n",
      "  3.65255713e-01  2.48614401e-01 -5.14616072e-01  2.34157577e-01\n",
      " -1.87686533e-01  6.26791641e-02 -3.89307231e-01 -1.00676906e+00\n",
      " -1.23767607e-01 -4.35872498e-04  3.16441387e-01 -9.61126834e-02\n",
      " -1.96278617e-01  2.14917939e-02 -3.70397002e-01  2.49399811e-01\n",
      "  5.62791824e-02  2.10989609e-01 -1.54752471e-02  3.53100486e-02\n",
      " -1.81153402e-01 -1.45582512e-01  6.63625240e-01 -6.50409535e-02\n",
      " -4.44586068e-01  4.70514208e-01  1.67913198e-01 -1.97715893e-01\n",
      " -2.57172287e-01 -6.16411082e-02 -3.46920520e-01  5.14425457e-01\n",
      " -8.27535316e-02  5.51929057e-01  2.25187361e-01  4.05966938e-01\n",
      "  3.53591830e-01  4.67578709e-01  1.03848808e-01  5.75147569e-01\n",
      " -1.82150885e-01  4.05117810e-01  2.00548366e-01 -4.01504897e-02\n",
      " -4.67177778e-02  5.29295921e-01 -2.71715015e-01 -2.69636321e+00\n",
      "  3.10868233e-01  1.14460163e-01 -4.11014557e-02  7.76335038e-03\n",
      "  3.02361757e-01  2.69384176e-01 -1.18807510e-01 -2.33403385e-01\n",
      "  3.24610710e-01  3.17406863e-01  3.46121103e-01 -8.36637095e-02\n",
      " -4.20324683e-01 -3.85011453e-03  1.63154185e-01  8.32931876e-01\n",
      " -2.23363638e-01  2.91345000e-01 -3.29402953e-01  4.11460608e-01\n",
      "  2.85194010e-01  2.05272269e+00 -2.58227378e-01  4.12255406e-01\n",
      "  1.37923837e-01  1.05185071e-02 -1.06933191e-01  4.60129142e-01\n",
      " -3.63450162e-02  2.73189425e-01  4.60076444e-02  1.22907436e+00\n",
      " -4.09719557e-01  1.27898857e-01  1.15239672e-01 -3.36248219e-01\n",
      "  4.51836407e-01  4.29785162e-01 -1.99759528e-01 -5.07047236e-01\n",
      "  7.21947700e-02 -7.83221185e-01 -2.11004987e-01  8.66250992e-01\n",
      "  2.18760073e-01 -4.23782133e-02 -7.75703967e-01 -3.55805159e-02\n",
      "  1.78951874e-01 -1.86514482e-01  3.65829431e-02 -7.39541501e-02\n",
      " -2.35198677e-01  1.29321560e-01  1.80087060e-01 -2.50748515e-01\n",
      " -4.25929576e-01 -1.81733504e-01 -2.37994611e-01 -5.09618856e-02\n",
      " -8.54088426e-01 -4.04384173e-03  4.04360265e-01  2.18954027e-01]\n",
      "\n",
      "Sentence: The quick brown fox jumps over the lazy dog.\n",
      "Embedding: [-0.6629451  -0.18165362  0.3498191   0.44428375  0.13734268  0.24091731\n",
      "  0.34972367  0.43101344  0.05086917  0.03221647  0.00888713 -0.83941966\n",
      "  0.38646126  0.5360752  -0.12137883  0.11615994 -0.11115343  0.08996305\n",
      " -0.6944847   0.30520156 -0.02559777 -0.5470331  -0.41486922 -0.14206262\n",
      "  0.2931336   0.15253957 -0.21228194 -0.04278428 -0.3382578  -1.4660301\n",
      "  0.31691524 -0.5954095   0.21001935 -0.50153947 -0.12533425 -0.24078216\n",
      " -0.11509346  0.43943143 -0.13225995  0.30465904  0.32082173 -0.01893257\n",
      " -0.17391966 -0.43693352 -0.06482982 -0.20791285 -0.46153224 -0.3314192\n",
      "  0.34327474 -0.39829707 -0.15839487 -0.30840206  0.32554173 -0.11309346\n",
      "  0.2981294  -0.08444727  0.52777296  0.13131876  0.1854562   0.28246018\n",
      "  0.24803992  0.3338605  -1.2746114   0.87782735  0.4585483   0.18235497\n",
      " -0.35134092 -0.3248637   0.06202226  0.15800771  0.12227743  0.5326513\n",
      "  0.08232541  0.36882743  0.36991724 -0.05916173  0.0439253   0.2435521\n",
      " -0.1154109   0.03551656 -0.11477654 -0.3528138  -0.4372159  -0.03177233\n",
      " -0.04846765 -0.26355496  0.19242758 -0.68462247  0.60363555  0.65485376\n",
      " -0.27518776 -0.0324862  -0.22713639  0.05893246 -0.32871225 -0.27904174\n",
      "  0.13086586 -0.03120605 -0.41131786  1.855629   -0.5072391   0.5042748\n",
      "  0.84885377 -0.4134227   0.3075852   0.08963144 -0.03979114  0.08687981\n",
      " -0.11142961  0.0589543   0.33233646 -0.05379909  0.36842266  0.03733022\n",
      "  0.2472549   0.01736072  0.06799685  0.75300103  0.06808224  0.01265026\n",
      "  0.18032454 -0.15520538  0.5260349  -0.2571503   0.11034188 -0.7913496\n",
      "  0.48793578  0.9397667   0.51951003  0.28783712  0.33385834 -0.6747287\n",
      "  0.09108683 -0.42703572  0.07055892  0.29703352 -0.09274469  0.07252112\n",
      "  0.225293   -0.4420584  -0.17506494 -1.3074368  -0.11834963 -0.85896343\n",
      " -0.19714923  0.22297083 -0.2009861   0.12485322 -0.61221904  0.21853459\n",
      " -0.02450799  0.19837792 -0.18724014 -0.16112906 -0.1708842   0.02431199\n",
      " -0.2902319   0.91321534 -0.12898849 -0.09183821 -0.2515337   0.01709852\n",
      " -0.12017721 -0.03957352  0.38756943 -0.5203666  -0.22504221  0.03100593\n",
      " -0.2049554  -0.23953553  0.142379    0.31059054 -0.95475477  0.2537481\n",
      "  0.4491038  -0.10200389 -0.61804706  0.03795989 -0.01308126 -0.44523633\n",
      "  0.68357396 -0.7931828  -0.63084096  0.5353397   0.37362623 -0.14830919\n",
      " -0.10710442  0.00912983  0.01998301  0.38726938 -0.22159623  0.15825845\n",
      " -0.00590746 -0.5617786  -0.62447727  0.11890507 -0.36021647 -0.12912802\n",
      "  0.1526912  -0.16987896  0.49217173 -0.32663354  0.22972734  0.00380568\n",
      "  0.65355796  0.10801058  0.08244663 -0.18579014  0.2983087   0.04025775\n",
      " -0.0461584  -0.03940429  0.1473202  -0.18040137 -0.18575053  0.37315384\n",
      " -0.26565668  0.17242603  0.27900028  0.2964525   0.54890245 -0.56031036\n",
      "  0.04807253 -1.792775    0.4733244  -0.16884808 -0.31301138  0.22613084\n",
      " -0.20656939  0.27326006 -0.6147676   0.47853637  0.5123072   0.528868\n",
      " -0.3804849  -0.23771094 -0.08716459  0.00513953  0.95105284  0.16781205\n",
      "  0.11904582  0.15985985 -0.02918851 -0.04759092  0.01888376  0.12498606\n",
      " -0.40822956  0.5006862  -0.3175843   2.000557    0.71991634  0.52385324\n",
      " -0.2797608   0.06007634  0.2630895  -0.7183828  -0.86573535  0.72486144\n",
      "  0.66689616  0.7021653  -0.443324   -0.2600667  -0.23307306 -0.56517684\n",
      "  0.44237092  0.06381697 -0.8652088  -0.10610563 -0.02326288 -0.4428079\n",
      " -0.08960343 -0.33778954  0.12896186  0.5785158  -0.13630839  0.49756333\n",
      "  0.33848977 -0.0066714   0.04086848 -0.51388437  0.21593578 -0.18417905\n",
      "  0.11129216 -0.23342204 -0.6650304   0.2798686  -0.17055069  0.3130783\n",
      "  0.0381998  -0.1233125  -0.3583525   0.20094681  0.18014129  0.02774104\n",
      "  0.47685775  0.32672027  0.06058824  0.24155955  0.04465558  0.35457316\n",
      "  0.01759273  0.19716583 -0.15074436  0.4032711  -0.6089738   0.19711907\n",
      " -0.02927386  0.2889467  -0.70075893  0.7823217  -0.28706902  0.33017907\n",
      " -0.757624    0.04025974  0.5046414  -0.33193228 -0.5182642  -0.23108469\n",
      " -0.02426799 -2.625172    0.10218281  0.03684564 -0.03662348 -0.07434877\n",
      "  0.19089627  0.12959518  0.12407289 -0.5073902  -0.04405533 -0.03054491\n",
      "  0.37549856  0.33715132  0.04787734 -0.04352545  0.07651443 -0.03855451\n",
      "  0.31443003 -0.08686048 -0.58088607  0.26579335 -0.07825147  1.8796488\n",
      " -0.524519    0.4038616   0.2593795  -0.168791    0.39704537  0.65021926\n",
      " -0.37603498  0.6238916  -0.08656093  0.72919697 -0.7378788  -0.04500779\n",
      "  0.35386518 -0.3476447   0.5314143   0.03512839 -0.29195878 -0.07317376\n",
      "  0.30971262  0.17497885 -0.5326459   0.74249774 -0.4796382  -0.71965593\n",
      " -0.3647449  -0.11681841  0.5413813  -0.19798549 -0.27197972 -0.52014947\n",
      "  0.06405341  0.22803764  0.20033127 -0.17576265 -0.18852127 -0.5127333\n",
      " -0.41101715  0.06763802 -0.6513091   0.14099194  0.36519304  1.0229415 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Our sentences to encode\n",
    "sentences = [\n",
    "    \"This framework generates embeddings for each input sentence\",\n",
    "    \"Sentences are passed as a list of string.\",\n",
    "    \"The quick brown fox jumps over the lazy dog.\"\n",
    "]\n",
    "\n",
    "# Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Print the embeddings\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cheetah is running behind its prey. (Score: 0.7710)\n",
      "A monkey is playing drums. (Score: 0.7556)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.util import semantic_search\n",
    "\n",
    "docs = [\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating a piece of bread.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "    \"A woman is playing violin.\",\n",
    "    \"Two men pushed carts through the woods.\",\n",
    "    \"A man is riding a white horse on an enclosed ground.\",\n",
    "    \"A monkey is playing drums.\",\n",
    "    \"A cheetah is running behind its prey.\",\n",
    "]\n",
    "\n",
    "docs_embeddings = model.encode(docs, convert_to_tensor=True)\n",
    "\n",
    "query = \"tell me about animals\"\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "hits = semantic_search(query_embedding, docs_embeddings, top_k=2)\n",
    "hits\n",
    "\n",
    "for hit in hits[0]:\n",
    "    print(docs[hit['corpus_id']], \"(Score: %.4f)\" % hit['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.6.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tiktoken) (2024.4.28)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def split_large_text(large_text, max_tokens):\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokenized_text = enc.encode(large_text)\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for token in tokenized_text:\n",
    "        current_chunk.append(token)\n",
    "        current_length += 1\n",
    "\n",
    "        if current_length >= max_tokens:\n",
    "            chunks.append(enc.decode(current_chunk).rstrip(' .,;'))\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(enc.decode(current_chunk).rstrip(' .,;'))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why use tokens?\n",
    "\n",
    "> By breaking words into smaller parts (tokens), LLMs can better handle new or unusual words by understanding their building blocks. It also helps the model grasp the nuances of language, such as different word forms and contextual meanings.\n",
    "\n",
    "[source](https://kelvin.legal/understanding-large-language-models-words-versus-tokens/#:~:text=By%20breaking%20words%20into%20smaller,word%20forms%20and%20contextual%20meanings.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "22\n",
      "[b'If', b' we', b' split', b' a', b' text', b' by', b' number', b' of', b' characters', b',', b' it', b' is', b' not', b' obvious', b' how', b' many', b' tokens', b' these', b' chunks', b' will', b' be', b'.']\n",
      "22\n",
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'If we split a text by number of characters, it is not obvious how many tokens these chunks will be.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "sent = \"If we split a text by number of characters, it is not obvious how many tokens these chunks will be.\"\n",
    "\n",
    "print(len(sent.split()))\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoded = enc.encode(sent)\n",
    "\n",
    "print(len(encoded))\n",
    "tokens = [enc.decode_single_token_bytes(x) for x in encoded]\n",
    "print(tokens)\n",
    "print(len(tokens))\n",
    "\n",
    "\n",
    "decoded = enc.decode(encoded)\n",
    "print(len(decoded.split()))\n",
    "decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If we split a text by number of characters',\n",
       " ' it is not obvious how many tokens these chunks will',\n",
       " ' be.\\nAnd at the same time if we want',\n",
       " ' to split a text into bigger possible chunks and keep',\n",
       " ' these chunks under certain LLM tokens limit, we',\n",
       " ' cannot operate by number of characters']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = \"\"\"If we split a text by number of characters, it is not obvious how many tokens these chunks will be.\n",
    "And at the same time if we want to split a text into bigger possible chunks and keep these chunks under certain LLM tokens limit, we cannot operate by number of characters.\"\"\"\n",
    "split_large_text(doc, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
