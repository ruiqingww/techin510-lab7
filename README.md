# Retrival Augumented Generation (RAG)

## What is embeddings?

Embeddings are numerical representations of data, typically used in natural language processing and machine learning. They map high-dimensional data, such as words or images, into a lower-dimensional continuous vector space. 

For instance, word embeddings like Word2Vec or GloVe encode words in such a way that similar words have similar vector representations. This facilitates tasks like classification, clustering, or semantic understanding by capturing relationships and patterns in the data. Embeddings are crucial for machine learning models, as they provide a dense, informative, and computable way to represent complex data features.

## Semantic search

Semantic search is a search method that focuses on understanding the meaning and context of search queries to provide more accurate and relevant results. It goes beyond matching keywords and aims to grasp the intent behind the search. By leveraging natural language processing (NLP), word embeddings, and knowledge graphs, semantic search identifies relationships between words and concepts.

## Large scale search

Large-scale search refers to the ability to search through vast amounts of data efficiently and effectively.  It involves handling large-scale datasets, often in the range of terabytes or petabytes, with numerous records. Techniques like distributed computing, indexing, parallel processing, and advanced algorithms are used to deliver fast and accurate search results.
